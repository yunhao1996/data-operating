{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import scipy\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from imageio import imread\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,input_flist,):\n",
    "        super(Dataset, self).__init__()\n",
    "\n",
    "        self.data = input_flist\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.load_item(index)\n",
    "\n",
    "        return item\n",
    "    \n",
    "    def load_item(self, index):\n",
    "        data = cv2.imread(self.data[index])\n",
    "        img = cv2.resize(data, dsize=(96,96), interpolation=cv2.INTER_AREA)\n",
    "        return self.to_tensor_norm(img) \n",
    "    \n",
    "    \n",
    "    def to_tensor_norm(self, img):\n",
    "        img_t = F.to_tensor(img).float()\n",
    "        img_t = F.normalize(img_t,[0.9414, 0.9414, 0.9414], [0.1626, 0.1626, 0.1626])  # 输入mean 和 std\n",
    "        return img_t\n",
    "\n",
    "a = Dataset('/home/ouc/64.jpg')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<U9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "b = '\\home\\ouc'\n",
    "print(type(b))\n",
    "a = np.array('\\home\\ouc')\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image \n",
    "import torch\n",
    "\n",
    "path = '/home/ouc/Flask/2024.jpg'\n",
    "img = Image.open(path).convert('RGB')\n",
    "# img = cv2.imread(path)\n",
    "# img1 = torch.from_numpy(img)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96,96)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.9414, 0.9414, 0.9414], [0.1626, 0.1626, 0.1626])])\n",
    "\n",
    "img2 = transform(img)\n",
    "print(type(img2))\n",
    "print(img2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "a = os.popen('python test.py --path /home/ouc/Flask/64.jpg')\n",
    "print('successful')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python py36pt11",
   "language": "python",
   "name": "py36pt11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
